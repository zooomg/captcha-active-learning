{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e146faa-c316-47bb-ae52-0d2a4f6adefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from model.resnet import resnet152, resnet34\n",
    "\n",
    "from utils.dataloader import CaptchaDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765da0be-f2fd-4ad5-9229-7b9889af75c6",
   "metadata": {},
   "source": [
    "# hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa051e42-ba1d-404f-a9af-15c7331b8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE = 'cuda' if CUDA else 'cpu'\n",
    "MODEL_PATH = './weights/resnet34_ceal'\n",
    "INIT_MODEL_PATH = './weights/resnet34_ceal_init'\n",
    "ACCURACY_PATH = './accuracy/CEAL_'\n",
    "BATCH_SIZE = 1\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4b3985-ebd5-49ad-97f3-7842245b929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_ANNOTATED_PERCENT = 0.1\n",
    "MAXIMUM_ITERATIONS = 29\n",
    "THRESHOLD_DECAY = 0.0033\n",
    "_DELTA = 0.05\n",
    "UNCERTAIN_SAMPLES_SIZE = 2000\n",
    "UNCERTAIN_CRITERIA = 'lc'\n",
    "COST_EFFECTIVE = True\n",
    "FINE_TUNNING_INTERVAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0848097-b68f-4a5b-8e31-bc79b10f2d4a",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "247807b6-b494-4aae-b38a-696da29bf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    # transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    #                      std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = CaptchaDataset('./Large_Captcha_Dataset', isFilter=True, isCrop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b64f795-b1c3-41f1-ac47-139437b970eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "test_split = 0.2\n",
    "validation_split = 0.1\n",
    "shuffling_dataset = True\n",
    "dataset_size = len(dataset) # 82328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f39569e8-3723-424f-84de-d1c6b51d94d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(dataset_size))\n",
    "test_split_size = int(np.floor(test_split * dataset_size)) # 16465\n",
    "validation_split_size = int(np.floor((dataset_size-test_split) * validation_split)) # 8232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8251267b-0c44-4821-8124-ff6406e09c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffling_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[test_split_size:], indices[:test_split_size]\n",
    "train_indices, val_indices = train_indices[validation_split_size:], train_indices[:validation_split_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29ccdbef-27b1-40da-bdb1-efa940022fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices) # 57631\n",
    "valid_sampler = SubsetRandomSampler(val_indices) # 8232\n",
    "test_sampler = SubsetRandomSampler(test_indices) # 16465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e99274-4fa7-41be-9c8e-0e4fa5dafc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "du = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "dl = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=valid_sampler)\n",
    "dtest = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79993a-b1b1-4826-8906-11e20da55402",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d727a93-1931-4c02-bbb9-b416c354d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "587e1207-72e6-4f23-a145-707ffe6ae747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, desc):\n",
    "    model.train()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    min_loss = 20.\n",
    "    stop_cnt = 0\n",
    "    for e in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        current_loss = []\n",
    "        current_val_loss = []\n",
    "\n",
    "        for (x, y) in tqdm(train_dataloader, desc):\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            y1, y2, y3, y4, y5 = y[:, 0], y[:, 1], y[:, 2], y[:, 3], y[:, 4]\n",
    "\n",
    "            pred1, pred2, pred3, pred4, pred5 = model(x)\n",
    "\n",
    "            loss1 = criterion(pred1, y1)\n",
    "            loss2 = criterion(pred2, y2)\n",
    "            loss3 = criterion(pred3, y3)\n",
    "            loss4 = criterion(pred4, y4)\n",
    "            loss5 = criterion(pred5, y5)\n",
    "            loss = loss1 + loss2 + loss3 + loss4 + loss5\n",
    "            current_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        current_loss = np.mean(current_loss).item()\n",
    "        loss_history.append(current_loss)\n",
    "\n",
    "        if current_loss < min_loss:\n",
    "            min_loss = current_loss\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "        ipd.clear_output(wait=True)\n",
    "        print(f\"{e+1}/{EPOCHS}, {time.time()-start_time:.2f} sec/epoch\")\n",
    "        print(f\"current loss={current_loss:.4f}\")\n",
    "        plt.figure(figsize=(20,1),dpi=120)\n",
    "        plt.scatter(np.arange(len(loss_history)), loss_history, label='train')\n",
    "        plt.legend(loc=1)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46a5d0-a6fe-4d05-aaa6-0465030b2a6a",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f5c17f-595d-4e37-9871-67d2641c331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataloader):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    pred_list = [[] for i in range(5)]\n",
    "    true_list = [[] for i in range(5)]\n",
    "    current_loss = []\n",
    "\n",
    "    for (x, y) in tqdm(test_dataloader, desc=\"eval\"):\n",
    "        with torch.no_grad():\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            y1, y2, y3, y4, y5 = y[:, 0], y[:, 1], y[:, 2], y[:, 3], y[:, 4]\n",
    "\n",
    "            pred1, pred2, pred3, pred4, pred5 = model(x)\n",
    "            \n",
    "            loss1 = criterion(pred1, y1)\n",
    "            loss2 = criterion(pred2, y2)\n",
    "            loss3 = criterion(pred3, y3)\n",
    "            loss4 = criterion(pred4, y4)\n",
    "            loss5 = criterion(pred5, y5)\n",
    "            loss = loss1 + loss2 + loss3 + loss4 + loss5\n",
    "            current_loss.append(loss.item())\n",
    "            \n",
    "            \n",
    "            pred1 = torch.argmax(pred1, -1)\n",
    "            pred2 = torch.argmax(pred2, -1)\n",
    "            pred3 = torch.argmax(pred3, -1)\n",
    "            pred4 = torch.argmax(pred4, -1)\n",
    "            pred5 = torch.argmax(pred5, -1)\n",
    "            \n",
    "\n",
    "            pred_list[0] += pred1.detach().cpu().tolist()\n",
    "            pred_list[1] += pred2.detach().cpu().tolist()\n",
    "            pred_list[2] += pred3.detach().cpu().tolist()\n",
    "            pred_list[3] += pred4.detach().cpu().tolist()\n",
    "            pred_list[4] += pred5.detach().cpu().tolist()\n",
    "\n",
    "            true_list[0] += y1.detach().cpu().tolist()\n",
    "            true_list[1] += y2.detach().cpu().tolist()\n",
    "            true_list[2] += y3.detach().cpu().tolist()\n",
    "            true_list[3] += y4.detach().cpu().tolist()\n",
    "            true_list[4] += y5.detach().cpu().tolist()\n",
    "            \n",
    "    pred_list = np.array(pred_list)\n",
    "    true_list = np.array(true_list)\n",
    "\n",
    "    loss = np.mean(current_loss).item()\n",
    "    accuracy = np.sum(pred_list==true_list, axis=1)/true_list.shape[-1]\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d2631-5de3-4fdf-9a99-6f0ec5aa5d67",
   "metadata": {},
   "source": [
    "# CEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e2473fc-bfcb-469b-9680-dfb6fa110518",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9110add-a14c-41f1-9a9c-f38827017331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(init_dataloader, test_dataloader):\n",
    "    model = resnet34()\n",
    "    if CUDA:\n",
    "        model = model.cuda()\n",
    "    if os.path.exists(INIT_MODEL_PATH):\n",
    "        print('Load initial model')\n",
    "        model.load_state_dict(torch.load(INIT_MODEL_PATH))\n",
    "    else:\n",
    "        print('Train initial model')\n",
    "        train(model, init_dataloader, desc=\"init train\")\n",
    "        torch.save(model.state_dict(), INIT_MODEL_PATH)\n",
    "    print('Eval initial model')\n",
    "    loss, acc = evaluate(model, test_dataloader)\n",
    "    print('Initial Test Loss: ', loss, '\\nInitial Test Accuracy: ', acc)\n",
    "    return model, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f204a89-fbc1-4e61-b40c-db7eefa2473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sampling\n",
    "def random_sampling(y_pred_prob, n_samples):\n",
    "    return np.random.choice(range(len(y_pred_prob)), n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e905a9c8-b2f7-45a9-9ab5-b069114e61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank all the unlabeled samples in an ascending order according to the least confidence\n",
    "def least_confidence(y_pred_prob, n_samples):\n",
    "    \"\"\"\n",
    "    y_pred_prob: (N, 5, 62)\n",
    "    \"\"\"\n",
    "    origin_index = np.arange(0, len(y_pred_prob)) # (N)\n",
    "    # max_prob = np.max(y_pred_prob, axis=1) # (N, 62)\n",
    "    max_prob = np.max(y_pred_prob, axis=2) # (N, 5)\n",
    "    mean_prob = np.mean(max_prob, axis=1) # (N,)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=1) # (N, 62)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=2) # (N, 5)\n",
    "\n",
    "    # lci = np.column_stack((origin_index,\n",
    "    #                        max_prob,\n",
    "    #                        pred_label))\n",
    "    lci = np.column_stack((origin_index,\n",
    "                       mean_prob))\n",
    "    lci = lci[lci[:, 1].argsort()]\n",
    "    return lci[:n_samples], lci[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c8126cb-7feb-4fd7-a7ef-2e5f7bbc4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank all the unlabeled samples in an ascending order according to the margin sampling\n",
    "def margin_sampling(y_pred_prob, n_samples):\n",
    "    origin_index = np.arange(0, len(y_pred_prob))\n",
    "    # margim_sampling = np.diff(-np.sort(y_pred_prob)[:, ::-1][:, :2]) # (N, 1)\n",
    "    margim_sampling = np.diff(-np.sort(y_pred_prob)[:, :, ::-1][:, :, :2]) # (N, 5, 1)\n",
    "    margim_sampling_mean = np.mean(margim_sampling, axis=1) # (N, 1)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=1)\n",
    "    # msi = np.column_stack((origin_index,\n",
    "    #                        margim_sampling,\n",
    "    #                        pred_label))\n",
    "    msi = np.column_stack((origin_index,\n",
    "                           margim_sampling_mean))\n",
    "    msi = msi[msi[:, 1].argsort()]\n",
    "    return msi[:n_samples], msi[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaa4713c-da9c-4469-a9b3-cb9e90dfa423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank all the unlabeled samples in an descending order according to their entropy\n",
    "def entropy(y_pred_prob, n_samples):\n",
    "    # entropy = stats.entropy(y_pred_prob.T)\n",
    "    # entropy = np.nan_to_num(entropy)\n",
    "    origin_index = np.arange(0, len(y_pred_prob))\n",
    "    # entropy = -np.nansum(np.multiply(y_pred_prob, np.log(y_pred_prob)), axis=1) # (4,)\n",
    "    entropy = -np.nansum(np.multiply(y_pred_prob, np.log(y_pred_prob)), axis=2) # (4, 5)\n",
    "    mean_entropy = np.mean(entropy, axis=1) # (4,)\n",
    "    \n",
    "    # pred_label = np.argmax(y_pred_prob, axis=1)\n",
    "    # eni = np.column_stack((origin_index,\n",
    "    #                        entropy,\n",
    "    #                        pred_label))\n",
    "    eni = np.column_stack((origin_index,\n",
    "                           mean_entropy))\n",
    "\n",
    "    eni = eni[(-eni[:, 1]).argsort()]\n",
    "    return eni[:n_samples], eni[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b584af64-44e3-4ea1-be59-0e357cd0fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wow(y_pred_prob, n_samples):\n",
    "    \"\"\"\n",
    "    y_pred_prob: (N, 5, 62)\n",
    "    \"\"\"\n",
    "    origin_index = np.arange(0, len(y_pred_prob)) # (N)\n",
    "    # max_prob = np.max(y_pred_prob, axis=1) # (N, 62)\n",
    "    max1_prob = np.max(y_pred_prob, axis=2) # (N, 5)\n",
    "    y_pred_prob[:,:,np.argmax(y_pred_prob, axis=2)]=0\n",
    "    max2_prob = np.max(y_pred_prob, axis=2)\n",
    "    max_prob = max2_prob/(max1_prob+1e-6)\n",
    "    mean_prob = np.mean(max_prob, axis=1) # (N,)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=1) # (N, 62)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=2) # (N, 5)\n",
    "\n",
    "    # lci = np.column_stack((origin_index,\n",
    "    #                        max_prob,\n",
    "    #                        pred_label))\n",
    "    lci = np.column_stack((origin_index,\n",
    "                       mean_prob))\n",
    "    lci = lci[lci[:, 1].argsort()]\n",
    "    return lci[:n_samples], lci[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47335897-5c7b-47e2-b8f7-ba3a88e38fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_confidence_samples(y_pred_prob, delta):\n",
    "    eni, eni_idx = entropy(y_pred_prob, len(y_pred_prob))\n",
    "    hcs = eni[eni[:, 1] < delta]\n",
    "    return hcs[:, 0].astype(int), hcs[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05f148ae-cb4e-48d3-87ff-0485287f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncertain_samples(y_pred_prob, n_samples, criteria):\n",
    "    if criteria == 'lc':\n",
    "        return least_confidence(y_pred_prob, n_samples)\n",
    "    elif criteria == 'ms':\n",
    "        return margin_sampling(y_pred_prob, n_samples)\n",
    "    elif criteria == 'en':\n",
    "        return entropy(y_pred_prob, n_samples)\n",
    "    elif criteria == 'rs':\n",
    "        return None, random_sampling(y_pred_prob, n_samples)\n",
    "    elif criteria == 'wow':\n",
    "        return wow(y_pred_prob, n_samples)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            'Unknown criteria value \\'%s\\', use one of [\\'rs\\',\\'lc\\',\\'ms\\',\\'en\\']' % criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5eb168c-f6db-46d2-9a41-912b5c762ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ceal():\n",
    "    model, loss, acc = initialize_model(dl, dtest)\n",
    "    losses.append(loss)\n",
    "    accs.append(acc)\n",
    "    _DELTA = 0.05\n",
    "    \n",
    "    for i in range(MAXIMUM_ITERATIONS):\n",
    "        y_pred_probs = []\n",
    "        for (x, y) in tqdm(du, desc='dataset(unlabeled)'):\n",
    "            x = x.to(DEVICE)\n",
    "            y_pred_prob = model(x)\n",
    "            y_pred_prob = list(map(lambda _y: (nn.functional.softmax(_y, dim=-1)).detach().cpu().numpy(), y_pred_prob))\n",
    "            y_pred_probs.append(y_pred_prob)\n",
    "\n",
    "        y_pred_probs = np.array(y_pred_probs)\n",
    "        y_pred_probs = np.transpose(y_pred_probs, (0, 2, 1, 3)).reshape(-1, 5, 62)\n",
    "\n",
    "        _, un_idx = get_uncertain_samples(y_pred_probs, UNCERTAIN_SAMPLES_SIZE, criteria=UNCERTAIN_CRITERIA)\n",
    "        \n",
    "        un_idx = [du.sampler.indices[idx] for idx in un_idx]\n",
    "        \n",
    "        dl.sampler.indices.extend(un_idx)\n",
    "        \n",
    "        print(\n",
    "            f'Update size of `dl` and `du` by adding uncertain {len(un_idx)} samples in `dl`\\nlen(dl): {len(dl.sampler.indices)}, len(du): {len(du.sampler.indices)}'\n",
    "        )\n",
    "        \n",
    "        if COST_EFFECTIVE:\n",
    "            print('COST_EFFECTIVE step')\n",
    "            hcs_idx, hcs_labels = get_high_confidence_samples(y_pred_prob, _DELTA)\n",
    "            \n",
    "            hcs_idx = [du.sampler.indices[idx] for idx in hcs_idx]\n",
    "            \n",
    "            hcs_idx = [x for x in hcs_idx if x not in list(set(un_idx) & set(hcs_idx))]\n",
    "            \n",
    "            dl.sampler.indices.extend(hcs_idx)\n",
    "            \n",
    "            for idx in range(len(hcs_idx)):\n",
    "                dl.dataset.y[hcs_idx[idx]] = hcs_labels[idx]\n",
    "        \n",
    "        if i % FINE_TUNNING_INTERVAL == 0 :\n",
    "            train(model, dl, desc=\"fine-tune\")\n",
    "            _DELTA -= (THRESHOLD_DECAY * FINE_TUNNING_INTERVAL)\n",
    "        \n",
    "        for val in un_idx:\n",
    "            du.sampler.indices.remove(val)\n",
    "        \n",
    "        loss, acc = evaluate(model, dtest)\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        \n",
    "        print(\n",
    "            \"Iteration: {}, len(dl): {}, len(du): {},\"\n",
    "            \" len(dh) {}, acc: {} \".format(\n",
    "                i, len(dl.sampler.indices),\n",
    "                len(du.sampler.indices), len(hcs_idx), acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "297902ae-6c3a-422d-b7e5-cad2d9267141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5, 254.26 sec/epoch\n",
      "current loss=6.6931\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2400x120 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 16465/16465 [01:19<00:00, 206.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2, len(dl): 11232, len(du): 54631, len(dh) 0, acc: [0.6102642  0.48095961 0.46316429 0.49662921 0.62933495] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 54631/54631 [04:44<00:00, 192.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update size of `dl` and `du` by adding uncertain 1000 samples in `dl`\n",
      "len(dl): 12232, len(du): 54631\n",
      "COST_EFFECTIVE step\n",
      "FINE_TUNNING step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                    | 782/12232 [00:18<04:26, 43.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_ceal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mrun_ceal\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m FINE_TUNNING_INTERVAL \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFINE_TUNNING step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     _DELTA \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m (THRESHOLD_DECAY \u001b[38;5;241m*\u001b[39m FINE_TUNNING_INTERVAL)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m un_idx:\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader)\u001b[0m\n\u001b[1;32m     29\u001b[0m     current_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     30\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 31\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(current_loss)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     34\u001b[0m loss_history\u001b[38;5;241m.\u001b[39mappend(current_loss)\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/optim/adamw.py:145\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 145\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/optim/_functional.py:134\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    132\u001b[0m exp_avg \u001b[38;5;241m=\u001b[39m exp_avgs[i]\n\u001b[1;32m    133\u001b[0m exp_avg_sq \u001b[38;5;241m=\u001b[39m exp_avg_sqs[i]\n\u001b[0;32m--> 134\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43mstate_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Perform stepweight decay\u001b[39;00m\n\u001b[1;32m    137\u001b[0m param\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m weight_decay)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_ceal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "784ec9e6-c6ba-4844-8fb9-e9b9e5eb4056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0316829192640762\\n-1.0686472696171214\\n-1.1986791068270872\\n0.058110692653088734\\n0.13870933128417434\\n0.7549735990029615\\n1.6617443653919945\\n0.99705748173351\\n-0.35347608562228\\n-1.5648751604893447'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.random.randn(10)\n",
    "\n",
    "\"\\n\".join(map(str, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8dd8a-a811-4832-876e-8e414c0061e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"log.txt\", \"w\") as f:\n",
    "    \"\\n\".join(map(str, accs))\n",
    "    \"\\n\".join(map(str, losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edeb358-ce10-4f8c-8b84-960f3a84aa93",
   "metadata": {},
   "source": [
    "# visalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397d05f-4478-4dbb-82d7-02e244b27e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8142d43-0414-4805-9964-cd6a720ccc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in dtest:\n",
    "    with torch.no_grad():\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        y1, y2, y3, y4, y5 = y[:, 0], y[:, 1], y[:, 2], y[:, 3], y[:, 4]\n",
    "\n",
    "        pred1, pred2, pred3, pred4, pred5 = model(x)\n",
    "        pred1 = torch.argmax(pred1, -1)\n",
    "        pred2 = torch.argmax(pred2, -1)\n",
    "        pred3 = torch.argmax(pred3, -1)\n",
    "        pred4 = torch.argmax(pred4, -1)\n",
    "        pred5 = torch.argmax(pred5, -1)\n",
    "        \n",
    "        y1 = list(map(lambda x: keys[x], y1))\n",
    "        y2 = list(map(lambda x: keys[x], y2))\n",
    "        y3 = list(map(lambda x: keys[x], y3))\n",
    "        y4 = list(map(lambda x: keys[x], y4))\n",
    "        y5 = list(map(lambda x: keys[x], y5))\n",
    "        \n",
    "        pred1 = list(map(lambda x: keys[x], pred1))\n",
    "        pred2 = list(map(lambda x: keys[x], pred2))\n",
    "        pred3 = list(map(lambda x: keys[x], pred3))\n",
    "        pred4 = list(map(lambda x: keys[x], pred4))\n",
    "        pred5 = list(map(lambda x: keys[x], pred5))\n",
    "        \n",
    "        \n",
    "        for idx in range(BATCH_SIZE):\n",
    "            true_str = f'{y1[idx]} {y2[idx]} {y3[idx]} {y4[idx]} {y5[idx]}'\n",
    "            pred_str = f'{pred1[idx]} {pred2[idx]} {pred3[idx]} {pred4[idx]} {pred5[idx]}'\n",
    "            plt.figure(figsize=(50,50))\n",
    "            plt.subplot(8, 8, idx+1)\n",
    "            plt.title(f'{true_str} / {pred_str}')\n",
    "            plt.imshow(x[idx].detach().cpu().permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1babc80-338b-4ba9-902b-eb5d81ebbec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
