{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e146faa-c316-47bb-ae52-0d2a4f6adefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from model.resnet import resnet152, resnet34\n",
    "\n",
    "from utils.dataloader import CaptchaDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765da0be-f2fd-4ad5-9229-7b9889af75c6",
   "metadata": {},
   "source": [
    "# hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa051e42-ba1d-404f-a9af-15c7331b8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE = 'cuda' if CUDA else 'cpu'\n",
    "MODEL_PATH = './weights/resnet34_ceal'\n",
    "INIT_MODEL_PATH = './weights/resnet34_ceal_init'\n",
    "ACCURACY_PATH = './accuracy/CEAL_'\n",
    "BATCH_SIZE = 1\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4b3985-ebd5-49ad-97f3-7842245b929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_ANNOTATED_PERCENT = 0.1\n",
    "MAXIMUM_ITERATIONS = 29\n",
    "THRESHOLD_DECAY = 0.0033\n",
    "_DELTA = 0.05\n",
    "UNCERTAIN_SAMPLES_SIZE = 2000\n",
    "UNCERTAIN_CRITERIA = 'lc'\n",
    "COST_EFFECTIVE = True\n",
    "FINE_TUNNING_INTERVAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0848097-b68f-4a5b-8e31-bc79b10f2d4a",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "247807b6-b494-4aae-b38a-696da29bf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    # transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    #                      std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = CaptchaDataset('./Large_Captcha_Dataset', isFilter=True, isCrop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b64f795-b1c3-41f1-ac47-139437b970eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "test_split = 0.2\n",
    "validation_split = 0.1\n",
    "shuffling_dataset = True\n",
    "dataset_size = len(dataset) # 82328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f39569e8-3723-424f-84de-d1c6b51d94d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(dataset_size))\n",
    "test_split_size = int(np.floor(test_split * dataset_size)) # 16465\n",
    "validation_split_size = int(np.floor((dataset_size-test_split) * validation_split)) # 8232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8251267b-0c44-4821-8124-ff6406e09c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffling_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[test_split_size:], indices[:test_split_size]\n",
    "train_indices, val_indices = train_indices[validation_split_size:], train_indices[:validation_split_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29ccdbef-27b1-40da-bdb1-efa940022fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices) # 57631\n",
    "valid_sampler = SubsetRandomSampler(val_indices) # 8232\n",
    "test_sampler = SubsetRandomSampler(test_indices) # 16465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e99274-4fa7-41be-9c8e-0e4fa5dafc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "du = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "dl = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=valid_sampler)\n",
    "dtest = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79993a-b1b1-4826-8906-11e20da55402",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d727a93-1931-4c02-bbb9-b416c354d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "587e1207-72e6-4f23-a145-707ffe6ae747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, desc):\n",
    "    model.train()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    min_loss = 20.\n",
    "    stop_cnt = 0\n",
    "    for e in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        current_loss = []\n",
    "        current_val_loss = []\n",
    "\n",
    "        for (x, y) in tqdm(train_dataloader, desc):\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            y1, y2, y3, y4, y5 = y[:, 0], y[:, 1], y[:, 2], y[:, 3], y[:, 4]\n",
    "\n",
    "            pred1, pred2, pred3, pred4, pred5 = model(x)\n",
    "\n",
    "            loss1 = criterion(pred1, y1)\n",
    "            loss2 = criterion(pred2, y2)\n",
    "            loss3 = criterion(pred3, y3)\n",
    "            loss4 = criterion(pred4, y4)\n",
    "            loss5 = criterion(pred5, y5)\n",
    "            loss = loss1 + loss2 + loss3 + loss4 + loss5\n",
    "            current_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        current_loss = np.mean(current_loss).item()\n",
    "        loss_history.append(current_loss)\n",
    "\n",
    "        if current_loss < min_loss:\n",
    "            min_loss = current_loss\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "        ipd.clear_output(wait=True)\n",
    "        print(f\"{e+1}/{EPOCHS}, {time.time()-start_time:.2f} sec/epoch\")\n",
    "        print(f\"current loss={current_loss:.4f}\")\n",
    "        plt.figure(figsize=(20,1),dpi=120)\n",
    "        plt.scatter(np.arange(len(loss_history)), loss_history, label='train')\n",
    "        plt.legend(loc=1)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46a5d0-a6fe-4d05-aaa6-0465030b2a6a",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f5c17f-595d-4e37-9871-67d2641c331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataloader):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    pred_list = [[] for i in range(5)]\n",
    "    true_list = [[] for i in range(5)]\n",
    "    current_loss = []\n",
    "\n",
    "    for (x, y) in tqdm(test_dataloader, desc=\"eval\"):\n",
    "        with torch.no_grad():\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            y1, y2, y3, y4, y5 = y[:, 0], y[:, 1], y[:, 2], y[:, 3], y[:, 4]\n",
    "\n",
    "            pred1, pred2, pred3, pred4, pred5 = model(x)\n",
    "            \n",
    "            loss1 = criterion(pred1, y1)\n",
    "            loss2 = criterion(pred2, y2)\n",
    "            loss3 = criterion(pred3, y3)\n",
    "            loss4 = criterion(pred4, y4)\n",
    "            loss5 = criterion(pred5, y5)\n",
    "            loss = loss1 + loss2 + loss3 + loss4 + loss5\n",
    "            current_loss.append(loss.item())\n",
    "            \n",
    "            \n",
    "            pred1 = torch.argmax(pred1, -1)\n",
    "            pred2 = torch.argmax(pred2, -1)\n",
    "            pred3 = torch.argmax(pred3, -1)\n",
    "            pred4 = torch.argmax(pred4, -1)\n",
    "            pred5 = torch.argmax(pred5, -1)\n",
    "            \n",
    "\n",
    "            pred_list[0] += pred1.detach().cpu().tolist()\n",
    "            pred_list[1] += pred2.detach().cpu().tolist()\n",
    "            pred_list[2] += pred3.detach().cpu().tolist()\n",
    "            pred_list[3] += pred4.detach().cpu().tolist()\n",
    "            pred_list[4] += pred5.detach().cpu().tolist()\n",
    "\n",
    "            true_list[0] += y1.detach().cpu().tolist()\n",
    "            true_list[1] += y2.detach().cpu().tolist()\n",
    "            true_list[2] += y3.detach().cpu().tolist()\n",
    "            true_list[3] += y4.detach().cpu().tolist()\n",
    "            true_list[4] += y5.detach().cpu().tolist()\n",
    "            \n",
    "    pred_list = np.array(pred_list)\n",
    "    true_list = np.array(true_list)\n",
    "\n",
    "    loss = np.mean(current_loss).item()\n",
    "    accuracy = np.sum(pred_list==true_list, axis=1)/true_list.shape[-1]\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d2631-5de3-4fdf-9a99-6f0ec5aa5d67",
   "metadata": {},
   "source": [
    "# CEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e2473fc-bfcb-469b-9680-dfb6fa110518",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9110add-a14c-41f1-9a9c-f38827017331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(init_dataloader, test_dataloader):\n",
    "    model = resnet34()\n",
    "    if CUDA:\n",
    "        model = model.cuda()\n",
    "    if os.path.exists(INIT_MODEL_PATH):\n",
    "        print('Load initial model')\n",
    "        model.load_state_dict(torch.load(INIT_MODEL_PATH))\n",
    "    else:\n",
    "        print('Train initial model')\n",
    "        train(model, init_dataloader, desc=\"init train\")\n",
    "        torch.save(model.state_dict(), INIT_MODEL_PATH)\n",
    "    print('Eval initial model')\n",
    "    loss, acc = evaluate(model, test_dataloader)\n",
    "    print('Initial Test Loss: ', loss, '\\nInitial Test Accuracy: ', acc)\n",
    "    return model, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f204a89-fbc1-4e61-b40c-db7eefa2473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sampling\n",
    "def random_sampling(y_pred_prob, n_samples):\n",
    "    return np.random.choice(range(len(y_pred_prob)), n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e905a9c8-b2f7-45a9-9ab5-b069114e61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank all the unlabeled samples in an ascending order according to the least confidence\n",
    "def least_confidence(y_pred_prob, n_samples):\n",
    "    \"\"\"\n",
    "    y_pred_prob: (N, 5, 62)\n",
    "    \"\"\"\n",
    "    origin_index = np.arange(0, len(y_pred_prob)) # (N)\n",
    "    # max_prob = np.max(y_pred_prob, axis=1) # (N, 62)\n",
    "    max_prob = np.max(y_pred_prob, axis=2) # (N, 5)\n",
    "    mean_prob = np.mean(max_prob, axis=1) # (N,)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=1) # (N, 62)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=2) # (N, 5)\n",
    "\n",
    "    # lci = np.column_stack((origin_index,\n",
    "    #                        max_prob,\n",
    "    #                        pred_label))\n",
    "    lci = np.column_stack((origin_index,\n",
    "                       mean_prob))\n",
    "    lci = lci[lci[:, 1].argsort()]\n",
    "    return lci[:n_samples], lci[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c8126cb-7feb-4fd7-a7ef-2e5f7bbc4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank all the unlabeled samples in an ascending order according to the margin sampling\n",
    "def margin_sampling(y_pred_prob, n_samples):\n",
    "    origin_index = np.arange(0, len(y_pred_prob))\n",
    "    # margim_sampling = np.diff(-np.sort(y_pred_prob)[:, ::-1][:, :2]) # (N, 1)\n",
    "    margim_sampling = np.diff(-np.sort(y_pred_prob)[:, :, ::-1][:, :, :2]) # (N, 5, 1)\n",
    "    margim_sampling_mean = np.mean(margim_sampling, axis=1) # (N, 1)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=1)\n",
    "    # msi = np.column_stack((origin_index,\n",
    "    #                        margim_sampling,\n",
    "    #                        pred_label))\n",
    "    msi = np.column_stack((origin_index,\n",
    "                           margim_sampling_mean))\n",
    "    msi = msi[msi[:, 1].argsort()]\n",
    "    return msi[:n_samples], msi[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaa4713c-da9c-4469-a9b3-cb9e90dfa423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank all the unlabeled samples in an descending order according to their entropy\n",
    "def entropy(y_pred_prob, n_samples):\n",
    "    # entropy = stats.entropy(y_pred_prob.T)\n",
    "    # entropy = np.nan_to_num(entropy)\n",
    "    origin_index = np.arange(0, len(y_pred_prob))\n",
    "    # entropy = -np.nansum(np.multiply(y_pred_prob, np.log(y_pred_prob)), axis=1) # (4,)\n",
    "    entropy = -np.nansum(np.multiply(y_pred_prob, np.log(y_pred_prob)), axis=2) # (4, 5)\n",
    "    mean_entropy = np.mean(entropy, axis=1) # (4,)\n",
    "    \n",
    "    # pred_label = np.argmax(y_pred_prob, axis=1)\n",
    "    # eni = np.column_stack((origin_index,\n",
    "    #                        entropy,\n",
    "    #                        pred_label))\n",
    "    eni = np.column_stack((origin_index,\n",
    "                           mean_entropy))\n",
    "\n",
    "    eni = eni[(-eni[:, 1]).argsort()]\n",
    "    return eni[:n_samples], eni[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b584af64-44e3-4ea1-be59-0e357cd0fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wow(y_pred_prob, n_samples):\n",
    "    \"\"\"\n",
    "    y_pred_prob: (N, 5, 62)\n",
    "    \"\"\"\n",
    "    origin_index = np.arange(0, len(y_pred_prob)) # (N)\n",
    "    # max_prob = np.max(y_pred_prob, axis=1) # (N, 62)\n",
    "    max1_prob = np.max(y_pred_prob, axis=2) # (N, 5)\n",
    "    y_pred_prob[:,:,np.argmax(y_pred_prob, axis=2)]=0\n",
    "    max2_prob = np.max(y_pred_prob, axis=2)\n",
    "    max_prob = max2_prob/(max1_prob+1e-6)\n",
    "    mean_prob = np.mean(max_prob, axis=1) # (N,)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=1) # (N, 62)\n",
    "    # pred_label = np.argmax(y_pred_prob, axis=2) # (N, 5)\n",
    "\n",
    "    # lci = np.column_stack((origin_index,\n",
    "    #                        max_prob,\n",
    "    #                        pred_label))\n",
    "    lci = np.column_stack((origin_index,\n",
    "                       mean_prob))\n",
    "    lci = lci[lci[:, 1].argsort()]\n",
    "    return lci[:n_samples], lci[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47335897-5c7b-47e2-b8f7-ba3a88e38fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_confidence_samples(y_pred_prob, delta):\n",
    "    eni, eni_idx = entropy(y_pred_prob, len(y_pred_prob))\n",
    "    hcs = eni[eni[:, 1] < delta]\n",
    "    return hcs[:, 0].astype(int), hcs[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05f148ae-cb4e-48d3-87ff-0485287f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncertain_samples(y_pred_prob, n_samples, criteria):\n",
    "    if criteria == 'lc':\n",
    "        return least_confidence(y_pred_prob, n_samples)\n",
    "    elif criteria == 'ms':\n",
    "        return margin_sampling(y_pred_prob, n_samples)\n",
    "    elif criteria == 'en':\n",
    "        return entropy(y_pred_prob, n_samples)\n",
    "    elif criteria == 'rs':\n",
    "        return None, random_sampling(y_pred_prob, n_samples)\n",
    "    elif criteria == 'wow':\n",
    "        return wow(y_pred_prob, n_samples)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            'Unknown criteria value \\'%s\\', use one of [\\'rs\\',\\'lc\\',\\'ms\\',\\'en\\']' % criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5eb168c-f6db-46d2-9a41-912b5c762ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ceal():\n",
    "    model, loss, acc = initialize_model(dl, dtest)\n",
    "    losses.append(loss)\n",
    "    accs.append(acc)\n",
    "    _DELTA = 0.05\n",
    "    \n",
    "    for i in range(MAXIMUM_ITERATIONS):\n",
    "        y_pred_probs = []\n",
    "        for (x, y) in tqdm(du, desc='dataset(unlabeled)'):\n",
    "            x = x.to(DEVICE)\n",
    "            y_pred_prob = model(x)\n",
    "            y_pred_prob = list(map(lambda _y: (nn.functional.softmax(_y, dim=-1)).detach().cpu().numpy(), y_pred_prob))\n",
    "            y_pred_probs.append(y_pred_prob)\n",
    "\n",
    "        y_pred_probs = np.array(y_pred_probs)\n",
    "        y_pred_probs = np.transpose(y_pred_probs, (0, 2, 1, 3)).reshape(-1, 5, 62)\n",
    "\n",
    "        _, un_idx = get_uncertain_samples(y_pred_probs, UNCERTAIN_SAMPLES_SIZE, criteria=UNCERTAIN_CRITERIA)\n",
    "        \n",
    "        un_idx = [du.sampler.indices[idx] for idx in un_idx]\n",
    "        \n",
    "        dl.sampler.indices.extend(un_idx)\n",
    "        \n",
    "        print(\n",
    "            f'Update size of `dl` and `du` by adding uncertain {len(un_idx)} samples in `dl`\\nlen(dl): {len(dl.sampler.indices)}, len(du): {len(du.sampler.indices)}'\n",
    "        )\n",
    "        \n",
    "        if COST_EFFECTIVE:\n",
    "            print('COST_EFFECTIVE step')\n",
    "            hcs_idx, hcs_labels = get_high_confidence_samples(y_pred_prob, _DELTA)\n",
    "            \n",
    "            hcs_idx = [du.sampler.indices[idx] for idx in hcs_idx]\n",
    "            \n",
    "            hcs_idx = [x for x in hcs_idx if x not in list(set(un_idx) & set(hcs_idx))]\n",
    "            \n",
    "            dl.sampler.indices.extend(hcs_idx)\n",
    "            \n",
    "            for idx in range(len(hcs_idx)):\n",
    "                dl.dataset.y[hcs_idx[idx]] = hcs_labels[idx]\n",
    "        \n",
    "        if i % FINE_TUNNING_INTERVAL == 0 :\n",
    "            train(model, dl, desc=\"fine-tune\")\n",
    "            _DELTA -= (THRESHOLD_DECAY * FINE_TUNNING_INTERVAL)\n",
    "        \n",
    "        for val in un_idx:\n",
    "            du.sampler.indices.remove(val)\n",
    "        \n",
    "        loss, acc = evaluate(model, dtest)\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        \n",
    "        print(\n",
    "            \"Iteration: {}, len(dl): {}, len(du): {},\"\n",
    "            \" len(dh) {}, acc: {} \".format(\n",
    "                i, len(dl.sampler.indices),\n",
    "                len(du.sampler.indices), len(hcs_idx), acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "297902ae-6c3a-422d-b7e5-cad2d9267141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load initial model\n",
      "Eval initial model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval:  73%|█████████████████████▊        | 11965/16465 [00:57<00:21, 206.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_ceal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mrun_ceal\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_ceal\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     model, loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m      4\u001b[0m     accs\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(init_dataloader, test_dataloader)\u001b[0m\n\u001b[1;32m     11\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), INIT_MODEL_PATH)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEval initial model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial Test Loss: \u001b[39m\u001b[38;5;124m'\u001b[39m, loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInitial Test Accuracy: \u001b[39m\u001b[38;5;124m'\u001b[39m, acc)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, loss, acc\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, test_dataloader)\u001b[0m\n\u001b[1;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     15\u001b[0m y1, y2, y3, y4, y5 \u001b[38;5;241m=\u001b[39m y[:, \u001b[38;5;241m0\u001b[39m], y[:, \u001b[38;5;241m1\u001b[39m], y[:, \u001b[38;5;241m2\u001b[39m], y[:, \u001b[38;5;241m3\u001b[39m], y[:, \u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m pred1, pred2, pred3, pred4, pred5 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss1 \u001b[38;5;241m=\u001b[39m criterion(pred1, y1)\n\u001b[1;32m     20\u001b[0m loss2 \u001b[38;5;241m=\u001b[39m criterion(pred2, y2)\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/captcha-active-learning/model/resnet.py:191\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    188\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m    190\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m--> 191\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m    193\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/captcha-active-learning/model/resnet.py:45\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     43\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 45\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/captcha/lib/python3.9/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    441\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    442\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_ceal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8dd8a-a811-4832-876e-8e414c0061e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"log_acc.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(map(str, accs)))\n",
    "with open(\"log_loss\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(map(str, losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edeb358-ce10-4f8c-8b84-960f3a84aa93",
   "metadata": {},
   "source": [
    "# visalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397d05f-4478-4dbb-82d7-02e244b27e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8142d43-0414-4805-9964-cd6a720ccc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in dtest:\n",
    "    with torch.no_grad():\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        y1, y2, y3, y4, y5 = y[:, 0], y[:, 1], y[:, 2], y[:, 3], y[:, 4]\n",
    "\n",
    "        pred1, pred2, pred3, pred4, pred5 = model(x)\n",
    "        pred1 = torch.argmax(pred1, -1)\n",
    "        pred2 = torch.argmax(pred2, -1)\n",
    "        pred3 = torch.argmax(pred3, -1)\n",
    "        pred4 = torch.argmax(pred4, -1)\n",
    "        pred5 = torch.argmax(pred5, -1)\n",
    "        \n",
    "        y1 = list(map(lambda x: keys[x], y1))\n",
    "        y2 = list(map(lambda x: keys[x], y2))\n",
    "        y3 = list(map(lambda x: keys[x], y3))\n",
    "        y4 = list(map(lambda x: keys[x], y4))\n",
    "        y5 = list(map(lambda x: keys[x], y5))\n",
    "        \n",
    "        pred1 = list(map(lambda x: keys[x], pred1))\n",
    "        pred2 = list(map(lambda x: keys[x], pred2))\n",
    "        pred3 = list(map(lambda x: keys[x], pred3))\n",
    "        pred4 = list(map(lambda x: keys[x], pred4))\n",
    "        pred5 = list(map(lambda x: keys[x], pred5))\n",
    "        \n",
    "        \n",
    "        for idx in range(BATCH_SIZE):\n",
    "            true_str = f'{y1[idx]} {y2[idx]} {y3[idx]} {y4[idx]} {y5[idx]}'\n",
    "            pred_str = f'{pred1[idx]} {pred2[idx]} {pred3[idx]} {pred4[idx]} {pred5[idx]}'\n",
    "            plt.figure(figsize=(50,50))\n",
    "            plt.subplot(8, 8, idx+1)\n",
    "            plt.title(f'{true_str} / {pred_str}')\n",
    "            plt.imshow(x[idx].detach().cpu().permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1babc80-338b-4ba9-902b-eb5d81ebbec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
